#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FinBERTæ¨¡å‹è·¯å¾„é…ç½®è„šæœ¬
åŸºäºå·²ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶é‡æ–°é…ç½®è·¯å¾„
"""

import os
import shutil
from pathlib import Path

def find_existing_model():
    """æŸ¥æ‰¾å·²å­˜åœ¨çš„FinBERTæ¨¡å‹æ–‡ä»¶"""
    print("ğŸ” æœç´¢å·²ä¸‹è½½çš„FinBERTæ¨¡å‹...")
    
    # æœç´¢å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        # å½“å‰é¡¹ç›®ç›®å½•
        Path("models/finbert-tone"),
        # ä¸Šçº§ç›®å½•
        Path("../models/finbert-tone"), 
        # Learningç›®å½•
        Path("../../models/finbert-tone"),
        Path("d:/Learning/models/finbert-tone"),
        # HuggingFaceç¼“å­˜ç›®å½•
        Path("~/.cache/huggingface/transformers").expanduser(),
    ]
    
    for base_path in possible_paths:
        if not base_path.exists():
            continue
            
        print(f"   æ£€æŸ¥è·¯å¾„: {base_path}")
        
        # ç›´æ¥æ£€æŸ¥æ–‡ä»¶
        model_files = ['config.json', 'pytorch_model.bin', 'vocab.txt', 'tokenizer_config.json']
        if all((base_path / f).exists() for f in model_files):
            print(f"âœ… æ‰¾åˆ°å®Œæ•´æ¨¡å‹: {base_path}")
            return base_path
        
        # æ£€æŸ¥HuggingFaceç¼“å­˜ç»“æ„
        if 'finbert-tone' in str(base_path):
            # æœç´¢snapshotsç›®å½•
            for root, dirs, files in os.walk(base_path):
                root_path = Path(root)
                if 'snapshots' in root_path.parts:
                    if all((root_path / f).exists() for f in model_files):
                        print(f"âœ… åœ¨ç¼“å­˜ä¸­æ‰¾åˆ°æ¨¡å‹: {root_path}")
                        return root_path
    
    return None

def copy_model_files(source_path, target_path):
    """å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ°é¡¹ç›®ç›®å½•"""
    print(f"ğŸ“ å¤åˆ¶æ¨¡å‹æ–‡ä»¶...")
    print(f"   æºè·¯å¾„: {source_path}")
    print(f"   ç›®æ ‡è·¯å¾„: {target_path}")
    
    # åˆ›å»ºç›®æ ‡ç›®å½•
    target_path.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶å¿…éœ€æ–‡ä»¶
    required_files = ['config.json', 'pytorch_model.bin', 'vocab.txt', 'tokenizer_config.json']
    
    for file_name in required_files:
        source_file = source_path / file_name
        target_file = target_path / file_name
        
        if source_file.exists():
            if target_file.exists():
                print(f"   âš ï¸ {file_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
            else:
                shutil.copy2(source_file, target_file)
                file_size = target_file.stat().st_size / (1024 * 1024)
                print(f"   âœ… å¤åˆ¶ {file_name} ({file_size:.1f}MB)")
        else:
            print(f"   âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
            return False
    
    return True

def verify_installation(model_path):
    """éªŒè¯æ¨¡å‹å®‰è£…"""
    print("ğŸ§ª éªŒè¯æ¨¡å‹å®‰è£…...")
    
    try:
        from transformers import AutoTokenizer, AutoModel
        
        # æµ‹è¯•åŠ è½½
        tokenizer = AutoTokenizer.from_pretrained(str(model_path), local_files_only=True)
        model = AutoModel.from_pretrained(str(model_path), local_files_only=True)
        
        # æµ‹è¯•ç¼–ç 
        test_text = "å¤®è¡Œé™æ¯æ”¿ç­–æ¨åŠ¨è‚¡å¸‚ä¸Šæ¶¨"
        inputs = tokenizer(test_text, return_tensors='pt', truncation=True, max_length=64)
        outputs = model(**inputs)
        
        print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"   ğŸ“Š è¾“å‡ºç»´åº¦: {outputs.last_hidden_state.shape[-1]}")
        print(f"   ğŸ“ æµ‹è¯•æ–‡æœ¬: '{test_text}'")
        
        return True
        
    except Exception as e:
        print(f"   âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def create_direct_link(source_path):
    """åˆ›å»ºç›´æ¥ä½¿ç”¨ç°æœ‰æ¨¡å‹çš„è·¯å¾„é…ç½®"""
    print("ğŸ”— é…ç½®ç›´æ¥è·¯å¾„...")
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config_content = f'''# FinBERTæ¨¡å‹è·¯å¾„é…ç½®
# æ­¤æ–‡ä»¶ç”±setup_finbert_from_existing.pyè‡ªåŠ¨ç”Ÿæˆ

FINBERT_MODEL_PATH = r"{source_path}"

# ä½¿ç”¨æ–¹æ³•ï¼š
# from pathlib import Path
# exec(open("finbert_config.py").read())
# model_path = Path(FINBERT_MODEL_PATH)
'''
    
    with open("finbert_config.py", "w", encoding="utf-8") as f:
        f.write(config_content)
    
    print(f"   âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: finbert_config.py")
    print(f"   ğŸ“ æ¨¡å‹è·¯å¾„: {source_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ FinBERTæ¨¡å‹è·¯å¾„é…ç½®è„šæœ¬")
    print("=" * 50)
    
    # 1. æŸ¥æ‰¾å·²å­˜åœ¨çš„æ¨¡å‹
    existing_model_path = find_existing_model()
    if not existing_model_path:
        print("âŒ æœªæ‰¾åˆ°å·²ä¸‹è½½çš„FinBERTæ¨¡å‹")
        print("å»ºè®®è¿è¡ŒåŸå§‹ä¸‹è½½è„šæœ¬æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹")
        return
    
    # 2. ç›®æ ‡è·¯å¾„
    target_path = Path("models/finbert-tone")
    
    # 3. æ£€æŸ¥ç›®æ ‡æ˜¯å¦å·²å­˜åœ¨
    if target_path.exists() and all((target_path / f).exists() for f in ['config.json', 'pytorch_model.bin']):
        print("âœ… é¡¹ç›®ç›®å½•ä¸­å·²å­˜åœ¨æ¨¡å‹æ–‡ä»¶")
    else:
        # 4. å¤åˆ¶æ–‡ä»¶
        if not copy_model_files(existing_model_path, target_path):
            print("âŒ å¤åˆ¶æ–‡ä»¶å¤±è´¥")
            return
    
    # 5. éªŒè¯å®‰è£…
    if verify_installation(target_path):
        print("\nğŸ‰ FinBERTæ¨¡å‹é…ç½®å®Œæˆ!")
        print("ç°åœ¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤:")
        print("  python train_offline.py      # è®­ç»ƒæ¨¡å‹")
        print("  python investment_advisor.py # æŠ•èµ„å†³ç­–åˆ†æ")
    else:
        print("\nâŒ é…ç½®å¤±è´¥")
        # åˆ›å»ºç›´æ¥é“¾æ¥ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        create_direct_link(existing_model_path)
        print("å·²åˆ›å»ºç›´æ¥è·¯å¾„é…ç½®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")

if __name__ == "__main__":
    main()
